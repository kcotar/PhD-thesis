\rb{V procesu kreativnega ustvarjanja.}

The fast increase in observational data seen in the last decade with the introduction of new and improved astronomical observational facilities requires new approaches to the exploration of acquired data. The old mentally of exact and painstaking analysis of individual objects have to be changed in order to grasp the full potential of large observational sets. On the other hand, large amounts of data and complex observational scenarios also lead to more complicated data reduction and analysis pipelines. As it is impossible to look through all acquired data and consider all variables, many computer algorithms have over the years been developed to help with those tasks. Of them, the most trending and occasionally misused are machine learning procedures of classification, clustering, and regression.

In this thesis, we have used some of the machine learning tools to explore large astronomical datasets, mainly collected as part of the \Gh\ and \G\ sky surveys. \ldots

Results presented in this thesis are also published as freely available catalogs and could serve as a starting point for many additional research that deal with exact physics behind identified peculiar stars.

The hype peak of the big data era in astronomy is still to come as many new telescopes and instruments are currently under development and construction. Until then, the \G\ satellite is continuously scanning our sky in order to bring us the most precise distances and movements for billions of stars that we are all warning for. The next grand data release is still at least a year away, but everyone is already questioning how much more can it do for science in the field of galactic archaeology. In our case, the updated distances could completely change the shape and structure of open clusters and reclassify exciting possible triple stars to dull single free-floating stars. Until then, we have to trust in the data and parameters currently disposable at our hands.